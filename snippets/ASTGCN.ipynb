{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "batch_size = 2048\n",
    "inputdir = '../data/'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Available CUDA devices:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load datasets from specified input directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(inputdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloop_sensor_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(inputdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloop_sensor_test_x.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m geo_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(inputdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_reference.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load datasets from specified input directory\n",
    "train_data = pd.read_csv(inputdir + 'loop_sensor_train.csv')\n",
    "test_data = pd.read_csv(inputdir + 'loop_sensor_test_x.csv')\n",
    "geo_data = pd.read_csv(inputdir + 'geo_reference.csv')\n",
    "\n",
    "# Merge geographic data with train and test datasets\n",
    "train_data = train_data.merge(geo_data, on='iu_ac', how='left')\n",
    "test_data = test_data.merge(geo_data, on='iu_ac', how='left')\n",
    "\n",
    "# Define adjacency matrix creation function and normalize features\n",
    "def create_adjacency_matrix(data, threshold=0.01):\n",
    "    coords = data[['geo_point_2d']].str.split(',', expand=True).astype(float).values\n",
    "    dist_matrix = np.sqrt((coords[:, np.newaxis, :] - coords[np.newaxis, :, :]) ** 2).sum(axis=2)\n",
    "    adj_matrix = (dist_matrix < threshold).astype(int)\n",
    "    return torch.tensor(adj_matrix, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create adjacency matrix and move it to the device\n",
    "adjacency_matrix = create_adjacency_matrix(train_data)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_data[['t_1h', 'etat_barre']])\n",
    "train_labels = train_data['q'].values\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32).to(device)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32).unsqueeze(1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = torch.matmul(adj, x)\n",
    "        x = self.fc(x)\n",
    "        return torch.relu(x)\n",
    "\n",
    "class TemporalAttentionLayer(nn.Module):\n",
    "    def __init__(self, num_steps):\n",
    "        super(TemporalAttentionLayer, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(num_steps))\n",
    "\n",
    "    def forward(self, x):\n",
    "        beta = torch.softmax(self.W, dim=0)\n",
    "        return torch.matmul(x, beta)\n",
    "\n",
    "class ASTGCN(nn.Module):\n",
    "    def __init__(self, num_features, num_nodes):\n",
    "        super(ASTGCN, self).__init__()\n",
    "        self.gconv1 = GraphConvolution(num_features, 16)\n",
    "        self.gconv2 = GraphConvolution(16, 32)\n",
    "        self.temporal_attention = TemporalAttentionLayer(num_steps=24)  # Assuming hourly data for one day\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gconv1(x, adj)\n",
    "        x = self.gconv2(x, adj)\n",
    "        x = self.temporal_attention(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and move model to the specified device\n",
    "model = ASTGCN(num_features=2, num_nodes=len(train_data['iu_ac'].unique())).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MAELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Dataset class for your data\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset and data loader\n",
    "train_dataset = TrafficDataset(train_features, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, adjacency_matrix)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_features = scaler.transform(test_data[['t_1h', 'etat_barre']])\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32).to(device)\n",
    "test_preds = model(test_features, adjacency_matrix)\n",
    "test_preds = test_preds.detach().cpu().numpy()\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    'iu_ac': test_data['iu_ac'],\n",
    "    't_1h': test_data['t_1h'],\n",
    "    'etat_barre': test_data['etat_barre'],\n",
    "    'estimate_q': test_preds.flatten()\n",
    "})\n",
    "submission.to_csv(inputdir + 'submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
