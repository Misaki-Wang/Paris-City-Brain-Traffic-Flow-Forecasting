{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda:1')\n",
    "# Directory for data and logs\n",
    "inputdir = '../data/'\n",
    "precesseddir = '../data/processed/'\n",
    "if not os.path.exists(precesseddir):\n",
    "    os.makedirs(precesseddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data = pd.read_csv(inputdir + 'geo_reference.csv', delimiter=';')\n",
    "graph_data = geo_data[['iu_ac', 'iu_nd_amont', 'iu_nd_aval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于所有重复的 'iu_ac'，'iu_nd_amont' 和 'iu_nd_aval' 均唯一对应。\n"
     ]
    }
   ],
   "source": [
    "def duplicate_check(data):\n",
    "    # 对 'iu_ac' 进行分组，并计算 'iu_nd_amont' 和 'iu_nd_aval' 的唯一值数量\n",
    "    unique_counts = data.groupby('iu_ac').agg({\n",
    "        'iu_nd_amont': 'nunique',\n",
    "        'iu_nd_aval': 'nunique'\n",
    "    })\n",
    "    # 检查所有 'iu_nd_amont' 和 'iu_nd_aval' 的唯一值数量是否都是 1\n",
    "    all_unique = (unique_counts['iu_nd_amont'] == 1) & (unique_counts['iu_nd_aval'] == 1)\n",
    "    # 如果 all_unique 中的所有值都是 True，则表示每个重复的 iu_ac 都有唯一对应的 iu_nd_amont 和 iu_nd_aval\n",
    "    if all_unique.all():\n",
    "        print(\"对于所有重复的 'iu_ac'，'iu_nd_amont' 和 'iu_nd_aval' 均唯一对应。\")\n",
    "    else:\n",
    "        print(\"存在一些 'iu_ac'，其 'iu_nd_amont' 或 'iu_nd_aval' 不是唯一对应的。\")\n",
    "\n",
    "duplicate_check(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_graph_data = graph_data.drop_duplicates(subset=['iu_ac', 'iu_nd_amont', 'iu_nd_aval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrix(data):\n",
    "    # Extract unique nodes and map them to an index\n",
    "    node_ids = pd.concat([data['iu_ac'], data['iu_nd_amont'], data['iu_nd_aval']]).unique()\n",
    "    node_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
    "    # Initialize an adjacency matrix of size NxN where N is the number of unique nodes\n",
    "    num_nodes = len(node_ids)\n",
    "    print(f'node_numbers: {num_nodes}')\n",
    "    adjacency_matrix = torch.zeros(num_nodes, num_nodes, dtype=torch.float32)\n",
    "    # Set edges based on upstream and downstream relationships\n",
    "    for _, row in data.iterrows():\n",
    "        node_idx = node_index[row['iu_ac']]\n",
    "        if row['iu_nd_amont'] in node_index:  # Check if upstream node is present\n",
    "            upstream_idx = node_index[row['iu_nd_amont']]\n",
    "            adjacency_matrix[upstream_idx][node_idx] = 1  # From upstream to current\n",
    "        if row['iu_nd_aval'] in node_index:  # Check if downstream node is present\n",
    "            downstream_idx = node_index[row['iu_nd_aval']]\n",
    "            adjacency_matrix[node_idx][downstream_idx] = 1  # From current to downstream\n",
    "    return adjacency_matrix\n",
    "\n",
    "# adj_matrix =  create_adjacency_matrix(geo_data)\n",
    "# print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_numbers: 4634\n"
     ]
    }
   ],
   "source": [
    "adj_matrix =  create_adjacency_matrix(u_graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.9997, total_elements:21473956 ,non_zero_num:6696\n",
      "3348\n",
      "1790\n"
     ]
    }
   ],
   "source": [
    "total_elements = adj_matrix.numel()  # 计算矩阵中的总元素数\n",
    "zero_elements = (adj_matrix == 0).sum().item()  # 计算矩阵中零元素的数量\n",
    "# 计算稀疏度\n",
    "non_zero = total_elements - zero_elements\n",
    "sparsity = zero_elements / total_elements\n",
    "\n",
    "print(f\"Sparsity: {sparsity:.4f}, total_elements:{total_elements} ,non_zero_num:{non_zero}\")\n",
    "print(len(geo_data['iu_ac'].unique()))\n",
    "print(len(geo_data['iu_nd_amont'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix_np = adj_matrix.numpy()  # 将 PyTorch 张量转换为 NumPy 数组\n",
    "# 保存矩阵到 .npz 文件\n",
    "np.savez_compressed(precesseddir+\"adjacency_matrix.npz\", adj_matrix=adj_matrix_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
